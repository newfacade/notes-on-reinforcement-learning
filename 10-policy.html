

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Policy Gradient &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=c5ced968eda925caa686" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=c5ced968eda925caa686"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '10-policy';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Advantage Actor-Critic (A2C)" href="11-a2c.html" />
    <link rel="prev" title="Deep Q-learning" href="09-dqn.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="01-intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="01-intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="02-mdp.html">Markov Decision Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-bellman.html">State values and Bellman equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-bellman-optimal.html">Optimal Policies and Bellman Optimality Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-iteration.html">Value iteration and policy iteration</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-monte-carlo.html">Monte Carlo Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-td.html">Temporal-Difference methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-q-learning.html">Q-learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-dqn.html">Deep Q-learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Policy Gradient</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-a2c.html">Advantage Actor-Critic (A2C)</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-trpo.html">Trust Region Policy Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-ppo.html">Proximal Policy Optimization</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F10-policy.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/10-policy.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Policy Gradient</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-simplest-policy-gradient">The Simplest Policy Gradient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-grad-log-prob-lemma">Expected Grad-Log-Prob Lemma</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dont-let-the-past-distract-you">Don’t Let the Past Distract You</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#baselines-in-policy-gradients">Baselines in Policy Gradients</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="policy-gradient">
<h1>Policy Gradient<a class="headerlink" href="#policy-gradient" title="Permalink to this heading">#</a></h1>
<section id="the-simplest-policy-gradient">
<h2>The Simplest Policy Gradient<a class="headerlink" href="#the-simplest-policy-gradient" title="Permalink to this heading">#</a></h2>
<p>Here, we consider the case of a stochastic, parameterized policy, <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span>. We aim to maximize the expected return <span class="math notranslate nohighlight">\(J(\pi_{\theta}) = \mathbb{E}_{\tau\sim\pi_{\theta}}[R(\tau)]\)</span>. For the purposes of this derivation, we’ll take <span class="math notranslate nohighlight">\(R(\tau)\)</span> to give the finite-horizon undiscounted return, but the derivation for the infinite-horizon discounted return setting is almost identical.</p>
<p>We would like to optimize the policy by gradient ascent:</p>
<div class="math notranslate nohighlight">
\[\theta_{k+1} = \theta_{k} + \alpha\nabla_{\theta}J(\pi_{\theta})|_{\theta_{k}}.\]</div>
<p>The gradient of policy performance, <span class="math notranslate nohighlight">\(\nabla_{\theta}J(\pi_{\theta})\)</span>, is called the policy gradient, and algorithms that optimize the policy this way are called policy gradient algorithms.</p>
<p>To actually use this algorithm, we need an expression for the policy gradient which we can numerically compute. This involves two steps:</p>
<ol class="arabic simple">
<li><p>deriving the analytical gradient of policy performance, which turns out to have the form of an expected value.</p></li>
<li><p>forming a sample estimate of that expected value, which can be computed with data from a finite number of agent-environment interaction steps.</p></li>
</ol>
<p>In this subsection, we’ll find the simplest form of that expression. In later subsections, we’ll show how to improve on the simplest form to get the version we actually use in standard policy gradient implementations.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\nabla_{\theta}J(\pi_{\theta}) &amp;= \nabla_{\theta}\mathbb{E}_{\tau\sim\pi_{\theta}}[R(\tau)]\\
&amp;= \nabla_{\theta}\int_{\tau}P(\tau|\theta)R(\tau) \\
&amp;= \int_{\tau}\nabla_{\theta}P(\tau|\theta)R(\tau) \\
&amp;= \int_{\tau}P(\tau|\theta)\nabla_{\theta}\log P(\tau|\theta)R(\tau)\\
&amp;= \mathbb{E}_{\tau\sim\pi_{\theta}}\left[\log P(\tau|\theta)R(\tau)\right]\\
&amp;= \mathbb{E}_{\tau\sim\pi_{\theta}}\left[\sum_{t=0}^{T}\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})R(\tau)\right]
\end{split}
\end{split}\]</div>
<p>This is an expectation, which means that we can estimate it with a sample mean. If we collect a set of trajectories <span class="math notranslate nohighlight">\(\mathcal{D} = \{\tau_{i}\}_{i=1,\dots,N}\)</span> where each trajectory is obtained by letting the agent act in the environment using the policy <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span>, the policy gradient can be estimated with</p>
<div class="math notranslate nohighlight">
\[\hat{g} = \frac{1}{|\mathcal{D}|}\sum_{\tau\in\mathcal{D}}\sum_{t=0}^{T}\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})R(\tau)\]</div>
<p>This last expression is the simplest version of the computable expression we desired. Assuming that we have represented our policy in a way which allows us to calculate <span class="math notranslate nohighlight">\(\log\pi_{\theta}(a_{t}|s_{t})\)</span>, and if we are able to run the policy in the environment to collect the trajectory dataset, we can compute the policy gradient and take an update step.</p>
</section>
<section id="expected-grad-log-prob-lemma">
<h2>Expected Grad-Log-Prob Lemma<a class="headerlink" href="#expected-grad-log-prob-lemma" title="Permalink to this heading">#</a></h2>
<p>In this subsection, we will derive an intermediate result which is extensively used throughout the theory of policy gradients. We will call it the Expected Grad-Log-Prob (EGLP) lemma.</p>
<p><strong>EGLP Lemma.</strong> Suppose that <span class="math notranslate nohighlight">\(P_{\theta}\)</span> is a parameterized probability distribution over a random variable, <span class="math notranslate nohighlight">\(x\)</span>. Then:</p>
<div class="math notranslate nohighlight">
\[\underset{x\sim P_{\theta}}{\mathbb{E}}[\nabla_{\theta}\log P_{\theta}(x)] = 0\]</div>
<p><strong>Proof.</strong> Recall that all probability distributions are normalized:</p>
<div class="math notranslate nohighlight">
\[\int_{x}P_{\theta}(x) = 1\]</div>
<p>Take the gradient of both sides of the normalization condition and use the log derivative trick to get:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
0 &amp;= \nabla_{\theta}1 \\
&amp;= \nabla_{\theta}\int_{x}P_{\theta}(x) \\
&amp;= \int_{x}\nabla_{\theta}P_{\theta}(x) \\
&amp;= \int_{x}P_{\theta}(x)\nabla_{\theta}\log P_{\theta}(x)
\end{split}
\end{split}\]</div>
</section>
<section id="dont-let-the-past-distract-you">
<h2>Don’t Let the Past Distract You<a class="headerlink" href="#dont-let-the-past-distract-you" title="Permalink to this heading">#</a></h2>
<p>Examine our most recent expression for the policy gradient:</p>
<div class="math notranslate nohighlight">
\[\nabla_{\theta}J(\pi_{\theta}) = \mathbb{E}_{\tau\sim\pi_{\theta}}\left[\sum_{t=0}^{T}\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})R(\tau)\right]\]</div>
<p>Taking a step with this gradient pushes up the log-probabilities of each action in proportion to <span class="math notranslate nohighlight">\(R(\tau)\)</span>, the sum of all rewards ever obtained. But this doesn’t make much sense.</p>
<p>Agents should really only reinforce actions on the basis of their consequences. Rewards obtained before taking an action have no bearing on how good that action was: only rewards that come after.</p>
<p>It turns out that this intuition shows up in the math, and we can show that the policy gradient can also be expressed by</p>
<div class="math notranslate nohighlight">
\[\nabla_{\theta}J(\pi_{\theta}) = \mathbb{E}_{\tau\sim\pi_{\theta}}\left[\sum_{t=0}^{T}\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})\sum_{t'=t}^{T}R(s_{t'}, a_{t'}, s_{t'+1})\right]\]</div>
<p>In this form, actions are only reinforced based on rewards obtained after they are taken.</p>
</section>
<section id="baselines-in-policy-gradients">
<h2>Baselines in Policy Gradients<a class="headerlink" href="#baselines-in-policy-gradients" title="Permalink to this heading">#</a></h2>
<p>An immediate consequence of the EGLP lemma is that for any function <span class="math notranslate nohighlight">\(b\)</span> which only depends on state,</p>
<div class="math notranslate nohighlight">
\[\underset{a_{t}\sim\pi_{\theta}}{\mathbb{E}}\left[\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})b(s_{t})\right] = 0\]</div>
<p>This allows us to add or subtract any number of terms like this from our expression for the policy gradient, without changing it in expectation:</p>
<div class="math notranslate nohighlight">
\[\nabla_{\theta}J(\pi_{\theta}) = \mathbb{E}_{\tau\sim\pi_{\theta}}\left[\sum_{t=0}^{T}\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})\left(\sum_{t'=t}^{T}R(s_{t'}, a_{t'}, s_{t'+1}) - b(s_{t})\right)\right]\]</div>
<p>Any function <span class="math notranslate nohighlight">\(b\)</span> used in this way is called a <strong>baseline.</strong></p>
<p>The most common choice of baseline is the on-policy value function <span class="math notranslate nohighlight">\(V^{\pi}(s_{t})\)</span>. Recall that this is the average return an agent gets if it starts in state <span class="math notranslate nohighlight">\(s_t\)</span> and then acts according to policy <span class="math notranslate nohighlight">\(\pi\)</span> for the rest of its life.</p>
<p>Empirically, the choice <span class="math notranslate nohighlight">\(b(s_t) = V^{\pi}(s_t)\)</span> has the desirable effect of reducing variance in the sample estimate for the policy gradient. This results in faster and more stable policy learning. It is also appealing from a conceptual angle: it encodes the intuition that if an agent gets what it expected, it should “feel” neutral about it.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="09-dqn.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Deep Q-learning</p>
      </div>
    </a>
    <a class="right-next"
       href="11-a2c.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Advantage Actor-Critic (A2C)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-simplest-policy-gradient">The Simplest Policy Gradient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-grad-log-prob-lemma">Expected Grad-Log-Prob Lemma</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dont-let-the-past-distract-you">Don’t Let the Past Distract You</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#baselines-in-policy-gradients">Baselines in Policy Gradients</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>