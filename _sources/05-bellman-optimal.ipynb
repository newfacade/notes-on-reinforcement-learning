{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccf77a4-b731-43aa-859f-192a37fb803b",
   "metadata": {},
   "source": [
    "# The Bellman Optimality Equation\n",
    "\n",
    "```{note}\n",
    "The ultimate goal of reinforcement learning is to seek optimal policies. It is, therefore,\n",
    "necessary to define what optimal policies are.<br>\n",
    "```\n",
    "\n",
    "Partial ordering between policies:\n",
    "\n",
    "$$\\pi_{1} \\ge \\pi_{2} \\Leftrightarrow V_{\\pi_1}(s) \\ge V_{\\pi_2}(s)\\quad \\forall s\\in\\mathcal{S}$$\n",
    "\n",
    "\n",
    "Some policies are not comparable!\n",
    "\n",
    "Optimal policy and optimal state-value function:\n",
    "\n",
    "$$V^{\\ast}(s) := \\max_{\\pi}V_{\\pi}(s) = V_{\\pi^{\\ast}}(s)\\quad\\forall s\\in\\mathcal{S}$$\n",
    "\n",
    "$\\pi^{\\ast}$ is a policy whose value function is the maximum out of all policy simultaneously for all states.\n",
    "\n",
    "$V^{\\ast}(s)$ shows the maximum expected discounted return that one can\n",
    "achieve from state $s$ with optimal play.\n",
    "\n",
    "This definition leads to many questions:\n",
    "\n",
    "* Existence: Does the optimal policy exist?\n",
    "* Uniqueness: Is the optimal policy unique?\n",
    "* Algorithm: How to obtain the optimal policy and the optimal state values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7e144-baea-41c4-b87e-92159bd40ef4",
   "metadata": {},
   "source": [
    "## Bellman optimality equation\n",
    "\n",
    "Bellman optimality equation (BOE):\n",
    "\n",
    "$$\n",
    "v(s) = \\underset{\\pi}{\\max} \\sum_{a\\in\\mathcal{A}}\\pi(a|s)\\left[R(s,a,s') + \\gamma\\sum_{s'\\in\\mathcal{S}}P(s'|s,a)v(s')\\right]\n",
    "$$\n",
    "\n",
    "Matrix form:\n",
    "\n",
    "$$v=\\underset{\\pi}{\\max}(r_{\\pi} + \\gamma P_{\\pi}v) = f(v)$$\n",
    "\n",
    "```{tip}\n",
    "BOE is a equation with unknown variable $v$.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd5d49-74f2-4c2a-acca-1673ac9a1c44",
   "metadata": {},
   "source": [
    "## Contraction mapping theorem\n",
    "\n",
    "*Definition*. Let $(X, d)$ be a metric space. Then a map $T: X\\to X$ is called a contraction mapping on $X$ if there exists $q\\in[0,1)$ such that\n",
    "\n",
    "$$d(Tx, Ty)\\le qd(x, y)$$\n",
    "\n",
    "for all $x, y\\in X$.\n",
    "\n",
    "````{prf:theorem} Banach fixed-point theorem\n",
    "Let $(X, d)$ be a non-empty complete metric space with a contraction mapping $T: X\\to X$. Then $T$ admits a unique fixed-point $x^{\\ast}$ in $X$ (i.e. $T(x^{\\ast})=x^{\\ast}$). Furthermore, $x^{\\ast}$ can be found as follows: start with an arbitrary element $x_{0}\\in X$ and define a sequence $\\{x_{n}\\}_{n\\in\\mathbb{N}}$ by $x_{n}=T(x_{n-1})$ for $n\\ge 1$. Then $\\lim_{n\\to\\infty}x_{n}=x^{\\ast}$.\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "Omit.\n",
    "````\n",
    "\n",
    "````{prf:theorem}\n",
    "The function $f(v) = \\underset{\\pi}{\\max}(r_{\\pi} + \\gamma P_{\\pi}v)$ is a contraction mapping. In particular, for any $v_{1},v_{2}\\in\\mathbb{R}^{|\\mathcal{S}|}$, it holds that\n",
    "\n",
    "```{math}\n",
    "\\|f(v_{1}) - f(v_{2})\\|_{\\infty} \\le \\gamma\\|v_{1}-v_{2}\\|_{\\infty},\n",
    "```\n",
    "\n",
    "where $\\gamma\\in(0, 1)$ is the discounted rate, and $\\|\\cdot\\|_{\\infty}$ is the maximum norm, which is the\n",
    "maximum absolute value of the elements of a vector.\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "Consider any two vectors $v_{1},v_{2}\\in\\mathbb{R}^{|\\mathcal{S}|}$, and suppose that $\\pi_{1}^{\\ast} = \\arg\\max_{\\pi}(r_{\\pi}+ \\gamma P_{\\pi}v_{1})$ and $\\pi_{2}^{\\ast} = \\arg\\max_{\\pi}(r_{\\pi}+ \\gamma P_{\\pi}v_{2})$. Then\n",
    "\n",
    "```{math}\n",
    "\\begin{split}\n",
    "f(v_{1}) &= \\underset{\\pi}{\\max}(r_{\\pi} + \\gamma P_{\\pi}v_{1}) = r_{\\pi_{1}^{\\ast}}+ \\gamma P_{\\pi_{1}^{\\ast}}v_{1} \\ge r_{\\pi_{2}^{\\ast}}+ \\gamma P_{\\pi_{2}^{\\ast}}v_{1} \\\\\n",
    "f(v_{2}) &= \\underset{\\pi}{\\max}(r_{\\pi} + \\gamma P_{\\pi}v_{2}) = r_{\\pi_{2}^{\\ast}}+ \\gamma P_{\\pi_{2}^{\\ast}}v_{2} \\ge r_{\\pi_{1}^{\\ast}}+ \\gamma P_{\\pi_{1}^{\\ast}}v_{2}\n",
    "\\end{split}\n",
    "```\n",
    "\n",
    "where $\\ge$ is an elementwise comparison. As a result,\n",
    "\n",
    "```{math}\n",
    "\\begin{split}\n",
    "f(v_{1}) - f(v_{2}) &= r_{\\pi_{1}^{\\ast}}+ \\gamma P_{\\pi_{1}^{\\ast}}v_{1} - (r_{\\pi_{2}^{\\ast}}+ \\gamma P_{\\pi_{2}^{\\ast}}v_{2}) \\\\ \n",
    "&\\le r_{\\pi_{1}^{\\ast}}+ \\gamma P_{\\pi_{1}^{\\ast}}v_{1} - (r_{\\pi_{1}^{\\ast}}+ \\gamma P_{\\pi_{1}^{\\ast}}v_{2}) \\\\\n",
    "&= \\gamma P_{\\pi_{1}^{\\ast}}(v_{1} - v_{2}).\n",
    "\\end{split}\n",
    "```\n",
    "\n",
    "Similarly, it can be shown that $f(v_{2}) - f(v_{1}) \\le \\gamma P_{\\pi_{2}^{\\ast}}(v_{2} - v_{1})$. Define\n",
    "\n",
    "```{math}\n",
    "z = \\max\\{ |\\gamma P_{\\pi_{1}^{\\ast}}(v_{1} - v_{2})|, |\\gamma P_{\\pi_{2}^{\\ast}}(v_{1} - v_{2})|\\} \\in\\mathbb{R}^{|\\mathcal{S}|}.\n",
    "```\n",
    "\n",
    "It then follows that\n",
    "\n",
    "```{math}\n",
    "\\|f(v_{1}) - f(v_{2})\\|_{\\infty} \\le \\|z\\|_{\\infty}.\n",
    "```\n",
    "\n",
    "On the other hand, suppose $z_{i}$ is the $i$-th entry of $z$, and $p_{i}^{T}$ and $q_{i}^{T}$ are the $i$-th row of $P_{\\pi_{1}^{\\ast}}$ and $P_{\\pi_{2}^{\\ast}}$, then\n",
    "\n",
    "```{math}\n",
    "z_{i} = \\max\\{\\gamma|p_{i}^{T}(v_{1} - v_{2})|, \\gamma|q_{i}^{T}(v_{1} - v_{2})|\\}\n",
    "```\n",
    "\n",
    "Since $p_{i}$ is a vector with all nonnegative elements and the sum of the elements is\n",
    "equal to one, it follows that\n",
    "\n",
    "```{math}\n",
    "|p_{i}^{T}(v_{1} - v_{2})| \\le p_{i}^{T}|(v_{1} - v_{2})| \\le \\|v_{1} - v_{2}\\|_{\\infty}\n",
    "```\n",
    "\n",
    "Similarly, we have $|q_{i}^{T}(v_{1} - v_{2})| \\le \\|v_{1} - v_{2}\\|_{\\infty}$. Therefore\n",
    "\n",
    "```{math}\n",
    "\\|z\\|_{\\infty} = \\max_{i}|z_{i}| \\le \\gamma\\|v_{1} - v_{2}\\|_{\\infty}.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efec65c-9713-4514-9e09-03d389633d6c",
   "metadata": {},
   "source": [
    "## Solving an optimal policy from the BOE\n",
    "\n",
    "Now we have, For the BOE $v=f(v)=\\max_{\\pi}(r_{\\pi}+ \\gamma P_{\\pi}v)$, there always exists a unique solution $v^{\\ast}$.\n",
    "\n",
    "Once the value of $v^{\\ast}$ has been obtained, we can easily obtain $\\pi^{\\ast}$ by solving \n",
    "\n",
    "$$\\pi^{\\ast} = \\arg\\max_{\\pi}(r_{\\pi}+\\gamma P_{\\pi}v^{\\ast}).$$\n",
    "\n",
    "````{prf:theorem}\n",
    "The solution $v^{\\ast}$ is the optimal state value, and $\\pi^{\\ast}$ is an optimal policy.\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "For any policy $\\pi$, it holds that\n",
    "\n",
    "```{math}\n",
    "v_{\\pi} = r_{\\pi} + \\gamma P_{\\pi}v_{\\pi}\n",
    "```\n",
    "\n",
    "Since\n",
    "\n",
    "```{math}\n",
    "v^{\\ast} = \\underset{\\pi}{\\max}(r_{\\pi} + \\gamma P_{\\pi}v^{\\ast}) = r_{\\pi^{\\ast}} + \\gamma P_{\\pi^{\\ast}}v^{\\ast} \\ge r_{\\pi} + \\gamma P_{\\pi}v^{\\ast}\n",
    "```\n",
    "\n",
    "we have\n",
    "\n",
    "```{math}\n",
    "v^{\\ast} - v_{\\pi} \\ge (r_{\\pi} + \\gamma P_{\\pi}v^{\\ast}) - (r_{\\pi} + \\gamma P_{\\pi}v_{\\pi}) = \\gamma P_{\\pi}(v^{\\ast} - v_{\\pi})\n",
    "```\n",
    "\n",
    "Repeated applying the above inequality gives $v^{\\ast} - v_{\\pi} \\ge \\gamma P_{\\pi}(v^{\\ast} - v_{\\pi}) \\ge \\gamma^{2} P_{\\pi}^{2}(v^{\\ast} - v_{\\pi})\\ge \\dots$. It follows that\n",
    "\n",
    "```{math}\n",
    "v^{\\ast} - v_{\\pi} \\ge \\lim_{n\\to\\infty}\\gamma^{n} P_{\\pi}^{n}(v^{\\ast} - v_{\\pi})=0\n",
    "```\n",
    "````\n",
    "\n",
    "Now we have:\n",
    "\n",
    "$$V^{\\ast}(s) = \\underset{\\pi}{\\max} \\sum_{a\\in\\mathcal{A}}\\pi(a|s)\\left[R(s,a,s') + \\gamma\\sum_{s'\\in\\mathcal{S}}P(s'|s,a)V^{\\ast}(s')\\right]$$\n",
    "\n",
    "```{tip}\n",
    "Now, it is clear why we must study the BOE: its solution corresponds to optimal state\n",
    "values and optimal policies.<br>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f676f8-044c-4cc2-9f98-896dff2e1b83",
   "metadata": {},
   "source": [
    "## Optimal action-value\n",
    "\n",
    "Definition of the optimal action-value:\n",
    "\n",
    "$$Q^{\\ast}(s, a) = \\max_{\\pi}Q_{\\pi}(s, a)$$\n",
    "\n",
    "It is easy to see from relation between V and Q function that:\n",
    "\n",
    "$$Q^{\\ast}(s, a) := \\sum_{s'\\in\\mathcal{S}}P(s'|s, a)\\left[R(s,a,s') + \\gamma V^{\\ast}(s')\\right]$$\n",
    "\n",
    "````{prf:theorem}\n",
    "For any $s\\in\\mathcal{S}$, the deterministic policy:\n",
    "\n",
    "```{math}\n",
    "\\pi_{\\text{greedy}}(a|s) =\n",
    "\\begin{cases}\n",
    "1,\\quad &a=\\arg\\max_{a'}Q^{\\ast}(a',s)\\\\\n",
    "0,\\quad &\\text{otherwise}\n",
    "\\end{cases}\n",
    "```\n",
    "\n",
    "is an optimal policy for solving the BOE.\n",
    "`````\n",
    "\n",
    "````{prf:proof}\n",
    "While the matrix-vector form of the optimal policy is $\\pi^{\\ast} = \\arg\\max_{\\pi}(r_{\\pi}+\\gamma P_{\\pi}v^{\\ast})$, its elementwise form is\n",
    "\n",
    "```{math}\n",
    "\\begin{aligned}\n",
    "\\pi^{\\ast}(s) &= \\arg\\max_{\\pi}\\sum_{a}\\pi(a|s)\\sum_{s'\\in\\mathcal{S}}P(s'|s, a)\\left[R(s,a,s') + \\gamma V^{\\ast}(s')\\right] \\\\\n",
    "& = \\arg\\max_{\\pi}\\sum_{a}\\pi(a|s)Q^{\\ast}(s, a)\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "It is clear that $\\sum_{a}\\pi(a|s)Q^{\\ast}(s, a)$ is maximized if $\\pi(s)$ selects the action with the greatest $Q^{\\ast}(s, a)$.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16035dd7-fb72-4d96-9e86-36b2bfc7e999",
   "metadata": {},
   "source": [
    "## Other forms of Bellman Optimality Equation\n",
    "\n",
    "Since $Q^{\\ast}$ and $V^{\\ast}$ are both related to the optimal policy $\\pi_{\\text{greedy}}$, we can obtain:\n",
    "\n",
    "$$V^{\\ast}(s) = \\max_{a}Q^{\\ast}(s, a)$$\n",
    "$$Q^{\\ast}(s, a) = \\sum_{s'\\in\\mathcal{S}}P(s'|s, a)\\left[R(s,a,s') + \\gamma V^{\\ast}(s')\\right]$$\n",
    "\n",
    "and\n",
    "\n",
    "$$V^{\\ast}(s) = \\max_{a}\\sum_{s'\\in\\mathcal{S}}P(s'|s, a)\\left[R(s,a,s') + \\gamma V^{\\ast}(s')\\right]$$\n",
    "$$Q^{\\ast}(s, a) = \\sum_{s'\\in\\mathcal{S}}P(s'|s, a)\\left[R(s,a,s') + \\gamma \\max_{a'}Q^{\\ast}(s', a')\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06fb3b7-ecf4-404b-abe4-f03310de1859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
