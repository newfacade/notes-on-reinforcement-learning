

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>The Reinforcement Learning Framework &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=c5ced968eda925caa686" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=c5ced968eda925caa686"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02-frame';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Two main approaches for solving RL problems" href="03-approach.html" />
    <link rel="prev" title="What is Reinforcement Learning?" href="01-intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="01-intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="01-intro.html">
                    What is Reinforcement Learning?
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The Reinforcement Learning Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-approach.html">Two main approaches for solving RL problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-bellman.html">The Bellman Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-bellman-optimal.html">The Bellman Optimality Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-dynamic.html">Dynamic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-monte-carlo-td.html">Monte Carlo vs Temporal Difference Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-q-learning.html">Q-learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-deep-q-learning.html">Deep Q-Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-dqn-torch.html">Deep Q-Learning with Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-policy.html">Policy Gradient</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F02-frame.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/02-frame.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Reinforcement Learning Framework</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-rl-process">The RL Process</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-reward-hypothesis-the-central-idea-of-reinforcement-learning">The reward hypothesis: the central idea of Reinforcement Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#observations-states-space">Observations/States Space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#action-space">Action Space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reward-and-return">Reward and Return</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formalism">Formalism</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-reinforcement-learning-framework">
<h1>The Reinforcement Learning Framework<a class="headerlink" href="#the-reinforcement-learning-framework" title="Permalink to this heading">#</a></h1>
<section id="the-rl-process">
<h2>The RL Process<a class="headerlink" href="#the-rl-process" title="Permalink to this heading">#</a></h2>
<p><img alt="" src="_images/frame1.jpeg" /></p>
<p>To understand the RL process, let’s imagine an agent learning to play a platform game:</p>
<p><img alt="" src="_images/frame2.jpeg" /></p>
<ul class="simple">
<li><p>Our Agent receives state <span class="math notranslate nohighlight">\(S_{0}\)</span> from the Environment — we receive the first frame of our game (Environment).</p></li>
<li><p>Based on that state <span class="math notranslate nohighlight">\(S_{0}\)</span>, the Agent takes action <span class="math notranslate nohighlight">\(A_{0}\)</span> — our Agent will move to the right.</p></li>
<li><p>The environment goes to a new state <span class="math notranslate nohighlight">\(S_{1}\)</span> — new frame.</p></li>
<li><p>The environment gives some reward <span class="math notranslate nohighlight">\(R_{1}\)</span> to the Agent — we’re not dead (Positive Reward +1).</p></li>
</ul>
<p>This RL loop outputs a sequence of state, action, reward and next state.</p>
</section>
<section id="the-reward-hypothesis-the-central-idea-of-reinforcement-learning">
<h2>The reward hypothesis: the central idea of Reinforcement Learning<a class="headerlink" href="#the-reward-hypothesis-the-central-idea-of-reinforcement-learning" title="Permalink to this heading">#</a></h2>
<p><span class="math notranslate nohighlight">\(\Rightarrow\)</span> Why is the goal of the agent to maximize the expected return?</p>
<p>Because RL is based on the reward hypothesis, which is that all goals can be described as the maximization of the expected return (expected cumulative reward).</p>
</section>
<section id="observations-states-space">
<h2>Observations/States Space<a class="headerlink" href="#observations-states-space" title="Permalink to this heading">#</a></h2>
<p>Observations/States are the information our agent gets from the environment. In the case of a video game, it can be a frame (a screenshot). In the case of the trading agent, it can be the value of a certain stock, etc.</p>
<p>There is a differentiation to make between observation and state, however:</p>
<ul>
<li><p>State <span class="math notranslate nohighlight">\(s\)</span>: is a complete description of the state of the world (there is no hidden information). In a fully observed environment.</p>
<p><img alt="" src="_images/frame4.jpeg" /></p>
<p>In a chess game, we have access to the whole board information, so we receive a state from the environment. In other words, the environment is fully observed.</p>
</li>
<li><p>Observation <span class="math notranslate nohighlight">\(o\)</span>: is a partial description of the state. In a partially observed environment.</p>
<p><img alt="" src="_images/frame5.jpeg" /></p>
<p>In Super Mario Bros, we only see the part of the level close to the player, so we receive an observation.</p>
</li>
</ul>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>In this course, we use the term “state” to denote both state and observation, but we will make the distinction in implementations.</p>
</div>
</section>
<section id="action-space">
<h2>Action Space<a class="headerlink" href="#action-space" title="Permalink to this heading">#</a></h2>
<p>The Action space is the set of all possible actions in an environment. The actions can come from a discrete or continuous space:</p>
<ul class="simple">
<li><p>Discrete space: the number of possible actions is finite. Again, in Super Mario Bros, we have a finite set of actions since we have only 4 directions.</p></li>
<li><p>Continuous space: the number of possible actions is infinite. A Self Driving Car agent has an infinite number of possible actions since it can turn left 20°, 21,1°, 21,2°, turn right 20°, etc.</p></li>
</ul>
</section>
<section id="reward-and-return">
<h2>Reward and Return<a class="headerlink" href="#reward-and-return" title="Permalink to this heading">#</a></h2>
<p>The reward function <span class="math notranslate nohighlight">\(R\)</span> is critically important in reinforcement learning. It depends on the current state of the world, the action just taken, and the next state of the world:</p>
<div class="math notranslate nohighlight">
\[r_{t+1} = R(s_{t}, a_{t}, s_{t+1})\]</div>
<p>although frequently this is simplified to just a dependence on the current state, <span class="math notranslate nohighlight">\(r_{t+1} = R(s_t)\)</span>, or state-action pair <span class="math notranslate nohighlight">\(r_{t+1} = R(s_t,a_t)\)</span>.</p>
<p>The goal of the agent is to maximize some notion of cumulative reward over a trajectory, but this actually can mean a few things. We’ll notate all of these cases with <span class="math notranslate nohighlight">\(R(\tau)\)</span>, and it will either be clear from context which case we mean, or it won’t matter (because the same equations will apply to all cases).</p>
<p>One kind of return is the finite-horizon undiscounted return, which is just the sum of rewards obtained in a fixed window of steps:</p>
<div class="math notranslate nohighlight">
\[R(\tau) = \sum_{t=1}^T r_t\]</div>
<p>Another kind of return is the infinite-horizon discounted return, which is the sum of all rewards ever obtained by the agent, but discounted by how far off in the future they’re obtained. This formulation of reward includes a discount factor <span class="math notranslate nohighlight">\(\gamma \in (0,1)\)</span>:</p>
<div class="math notranslate nohighlight">
\[R(\tau) = \sum_{t=1}^{\infty} \gamma^t r_t\]</div>
<p>Why would we ever want a discount factor, though? Don’t we just want to get all rewards? We do, but the discount factor is both intuitively appealing and mathematically convenient. On an intuitive level: cash now is better than cash later. Mathematically: an infinite-horizon sum of rewards may not converge to a finite value, and is hard to deal with in equations. But with a discount factor and under reasonable conditions, the infinite sum converges.</p>
</section>
<section id="formalism">
<h2>Formalism<a class="headerlink" href="#formalism" title="Permalink to this heading">#</a></h2>
<p>So far, we’ve discussed the agent’s environment in an informal way, but if you try to go digging through the literature, you’re likely to run into the standard mathematical formalism for this setting: Markov Decision Processes (MDPs). An MDP is a 5-tuple, <span class="math notranslate nohighlight">\(\langle S, A, R, P, \rho_0 \rangle\)</span>, where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S\)</span> is the set of all valid states,</p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span> is the set of all valid actions,</p></li>
<li><p><span class="math notranslate nohighlight">\(R : S \times A \times S \to \mathbb{R}\)</span> is the reward function, with <span class="math notranslate nohighlight">\(r_{t+1} = R(s_t, a_t, s_{t+1})\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(P : S \times A \to \mathcal{P}(S)\)</span> is the transition probability function, with <span class="math notranslate nohighlight">\(P(s'|s,a)\)</span> being the probability of transitioning into state <span class="math notranslate nohighlight">\(s'\)</span> if you start in state <span class="math notranslate nohighlight">\(s\)</span> and take action <span class="math notranslate nohighlight">\(a\)</span>,</p></li>
<li><p>and <span class="math notranslate nohighlight">\(\rho_0\)</span> is the starting state distribution.</p></li>
</ul>
<p>The name Markov Decision Process refers to the fact that the system obeys the Markov property: transitions only depend on the most recent state and action, and no prior history.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="01-intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">What is Reinforcement Learning?</p>
      </div>
    </a>
    <a class="right-next"
       href="03-approach.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Two main approaches for solving RL problems</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-rl-process">The RL Process</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-reward-hypothesis-the-central-idea-of-reinforcement-learning">The reward hypothesis: the central idea of Reinforcement Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#observations-states-space">Observations/States Space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#action-space">Action Space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reward-and-return">Reward and Return</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formalism">Formalism</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>