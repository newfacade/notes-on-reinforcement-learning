

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Dynamic Programming &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '06-dynamic';</script>
    <link rel="shortcut icon" href="_static/github.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Monte Carlo vs Temporal Difference Learning" href="07-monte-carlo-td.html" />
    <link rel="prev" title="The Bellman Optimality Equation" href="05-bellman-optimal.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="01-intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/shuishen-min.jpeg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/shuishen-min.jpeg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="01-intro.html">
                    What is Reinforcement Learning?
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="02-frame.html">The Reinforcement Learning Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-approach.html">Two main approaches for solving RL problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-bellman.html">The Bellman Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-bellman-optimal.html">The Bellman Optimality Equation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Dynamic Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-monte-carlo-td.html">Monte Carlo vs Temporal Difference Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-q-learning.html">Q-learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-deep-q-learning.html">Deep Q-Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-dqn-torch.html">Deep Q-Learning with Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-policy.html">Policy Gradient</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-actor-critic.html">Actor-Critic Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-trpo.html">TRPO</a></li>
<li class="toctree-l1"><a class="reference internal" href="14-gae.html">Generalized Advantage Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="15-ppo.html">Proximal Policy Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="16-ppo-torch.html">PPO with CleanRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="17-ppo-trl.html">PPO with TRL</a></li>



</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F06-dynamic.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/06-dynamic.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Dynamic Programming</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-evaluation">Policy Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-improvement">Policy Improvement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-iteration">Policy Iteration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#value-iteration">Value Iteration</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="dynamic-programming">
<h1>Dynamic Programming<a class="headerlink" href="#dynamic-programming" title="Permalink to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The term dynamic programming (DP) refers to a collection of algorithms that can be
used to compute optimal policies given a perfect model of the environment as a Markov
decision process (MDP). Classical DP algorithms are of limited utility in reinforcement
learning both because of their assumption of a perfect model and because of their great
computational expense, but they are still important theoretically. DP provides an essential
foundation for the understanding of the methods presented in the rest of this book. In
fact, all of these methods can be viewed as attempts to achieve much the same effect as
DP, only with less computation and without assuming a perfect model of the environment.</p>
</div>
<section id="policy-evaluation">
<h2>Policy Evaluation<a class="headerlink" href="#policy-evaluation" title="Permalink to this heading">#</a></h2>
<p>First we consider how to compute the state-value function <span class="math notranslate nohighlight">\(V_{\pi}\)</span> for an arbitrary policy <span class="math notranslate nohighlight">\(\pi\)</span>. This is called policy evaluation in the DP literature. Recall the Bellman equation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
V_{\pi}(s) &amp;= \mathbb{E}_{\pi}[R_{t+1} + \gamma V_{\pi}(S_{t+1})|S_{t}=s]\\
&amp;= \sum_{a}\pi(a|s)\sum_{s'\in\mathcal{S}}P(s'|s, a)\left[R(s,a,s') + \gamma V_{\pi}(s')\right]
\end{aligned}
\end{split}\]</div>
<p>If the environment’s dynamics are completely known, then it is a system of <span class="math notranslate nohighlight">\(|S|\)</span> linear equations in <span class="math notranslate nohighlight">\(|S|\)</span> unknowns. In principle, its solution is a straightforward computation. For our purposes, iterative solution methods
are most suitable. The initial approximation, <span class="math notranslate nohighlight">\(V_{0}\)</span>, is chosen arbitrarily, and each successive approximation is obtained by using the Bellman equation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
V_{k+1}(s) &amp;= \mathbb{E}_{\pi}[R_{t+1} + \gamma V_{k}(S_{t+1})|S_{t}=s]\\
&amp;= \sum_{a}\pi(a|s)\sum_{s'\in\mathcal{S}}P(s'|s, a)\left[R(s,a,s') + \gamma V_{k}(s')\right]
\end{aligned}
\end{split}\]</div>
<p>Clearly, <span class="math notranslate nohighlight">\(V_{k} = V_{\pi}\)</span> is a fixed point for this update rule. Indeed, the sequence <span class="math notranslate nohighlight">\(\{V_{k}\}\)</span> can be shown in general to converge to <span class="math notranslate nohighlight">\(V_{\pi}\)</span> as <span class="math notranslate nohighlight">\(k\to\infty\)</span>.</p>
</section>
<section id="policy-improvement">
<h2>Policy Improvement<a class="headerlink" href="#policy-improvement" title="Permalink to this heading">#</a></h2>
<p>Our reason for computing the value function for a policy is to help find better policies. Suppose we have determined the value function <span class="math notranslate nohighlight">\(V_{\pi}\)</span> for an arbitrary deterministic policy <span class="math notranslate nohighlight">\(\pi\)</span>. For some state <span class="math notranslate nohighlight">\(s\)</span> we would like to know whether or not we should change the policy
to deterministically choose an action <span class="math notranslate nohighlight">\(a\ne \pi(s)\)</span>.</p>
<div class="proof theorem admonition" id="theorem-0">
<p class="admonition-title"><span class="caption-number">Theorem 5 </span> (Policy improvement theorem)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\pi\)</span> and <span class="math notranslate nohighlight">\(\pi'\)</span> be any pair of deterministic policies such that, for all <span class="math notranslate nohighlight">\(s\in\mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[Q_{\pi}(s, \pi'(s)) \ge V_{\pi}(s)\]</div>
<p>Then the policy <span class="math notranslate nohighlight">\(\pi'\)</span> must be as good as, or better than, <span class="math notranslate nohighlight">\(\pi\)</span>.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. The idea behind the proof of the policy improvement theorem is easy to understand, we keep expanding the <span class="math notranslate nohighlight">\(Q_{\pi}\)</span> side and reapplying the inequality:</p>
<p><span class="math notranslate nohighlight">\(
\begin{aligned}
V_{\pi}(s) &amp;\le Q_{\pi}(s, \pi'(s)) \\
&amp;=\mathbb{E}_{\pi}[R_{t+1} + \gamma V_{\pi}(S_{t+1})|S_{t}=s,A_{t}=\pi'(s)]\\
&amp;=\mathbb{E}_{\pi'}[R_{t+1} + \gamma V_{\pi}(S_{t+1})|S_{t}=s]\\
&amp;\le\mathbb{E}_{\pi'}[R_{t+1} + \gamma Q_{\pi}(S_{t+1},\pi'(S_{t+1}))|S_{t}=s]\\
&amp;=\mathbb{E}_{\pi'}[R_{t+1} + \gamma \mathbb{E}[R_{t+2}+\gamma V_{\pi}(S_{t+2})|S_{t+1},A_{t+1}=\pi'(S_{t+1})]|S_{t}=s]\\
&amp;=\mathbb{E}_{\pi'}[R_{t+1} + \gamma R_{t+2} + \gamma^{2}V_{\pi}(S_{t+2})|S_{t}=s]\\
&amp;\le\mathbb{E}_{\pi'}[R_{t+1} + \gamma R_{t+2} + \gamma^{2} R_{t+3} + \gamma^{3}V_{\pi}(S_{t+3})|S_{t}=s]\\
&amp;\vdots\\
&amp;\le\mathbb{E}_{\pi'}[R_{t+1} + \gamma R_{t+2} + \gamma^{2} R_{t+3} + \gamma^{3}R_{t+4}+\dots|S_{t}=s]\\
&amp;=V_{\pi'}(s)
\end{aligned}
\)</span></p>
</div>
<p>Given a deterministic policy <span class="math notranslate nohighlight">\(\pi\)</span>, consider the new greedy policy <span class="math notranslate nohighlight">\(\pi'\)</span> given by</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\pi'(s) := \arg\max_{a}Q_{\pi}(s, a)
\end{aligned}
\]</div>
<p>The process of making a new policy that improves on an original policy, by making it greedy with respect to the value function of
the original policy, is called policy improvement. Suppose the new greedy policy, <span class="math notranslate nohighlight">\(\pi'\)</span>, is as good as, but not better than, the old policy <span class="math notranslate nohighlight">\(\pi\)</span>. Then <span class="math notranslate nohighlight">\(V_{\pi}=V_{\pi'}\)</span>, the Bellman optimality equations are satisfied, and therefore, <span class="math notranslate nohighlight">\(V_{\pi'}\)</span> must be <span class="math notranslate nohighlight">\(V_{\ast}\)</span>, and both <span class="math notranslate nohighlight">\(\pi\)</span> and <span class="math notranslate nohighlight">\(\pi'\)</span> must be optimal policies..</p>
<p>So far we have considered the special case of deterministic policies. In the general case, a stochastic policy <span class="math notranslate nohighlight">\(\pi\)</span> specifies probabilities, <span class="math notranslate nohighlight">\(\pi(a|s)\)</span>, for taking each action, <span class="math notranslate nohighlight">\(a\)</span>, in each state, <span class="math notranslate nohighlight">\(s\)</span>. The policy improvement theorem carries through as stated for the stochastic case.</p>
</section>
<section id="policy-iteration">
<h2>Policy Iteration<a class="headerlink" href="#policy-iteration" title="Permalink to this heading">#</a></h2>
<p>Once a policy, <span class="math notranslate nohighlight">\(\pi\)</span>, has been improved using <span class="math notranslate nohighlight">\(V_{\pi}\)</span> to yield a better policy, <span class="math notranslate nohighlight">\(\pi'\)</span>, we can then
compute <span class="math notranslate nohighlight">\(V_{\pi'}\)</span> and improve it again to yield an even better <span class="math notranslate nohighlight">\(\pi''\)</span>. We can thus obtain a
sequence of monotonically improving policies and value functions:</p>
<div class="math notranslate nohighlight">
\[
\pi_{0}\overset{E}{\longrightarrow} V_{\pi_{0}}\overset{I}{\longrightarrow} \pi_{1}\overset{E}{\longrightarrow} V_{\pi_{1}}\overset{I}{\longrightarrow} \dots
\]</div>
<p>where <span class="math notranslate nohighlight">\(\overset{E}{\longrightarrow}\)</span> denotes a policy evaluation and <span class="math notranslate nohighlight">\(\overset{I}{\longrightarrow}\)</span> denotes a policy improvement. Each
policy is guaranteed to be a strict improvement over the previous one (unless it is already
optimal). This process must converge to an optimal policy and optimal value function.</p>
</section>
<section id="value-iteration">
<h2>Value Iteration<a class="headerlink" href="#value-iteration" title="Permalink to this heading">#</a></h2>
<p>One drawback to policy iteration is that each of its iterations involves policy evaluation, which may itself be a iterative computation.</p>
<p>In fact, the policy evaluation step of policy iteration can be truncated in several ways without losing the convergence guarantees of policy iteration. One important special case is when policy evaluation is stopped after just one update of each state. This algorithm is called value iteration. It can be written as a particularly simple update
operation that combines the policy improvement and truncated policy evaluation steps:</p>
<div class="math notranslate nohighlight">
\[
V_{k+1}(s) := \max_{a}\mathbb{E}[R_{t+1} + \gamma V_{k}(S_{t+1})|S_{t}=s,A_{t}=a]
\]</div>
<p>Another way of understanding value iteration is by reference to the Bellman optimality
equation. Note that value iteration is obtained simply by turning the Bellman
optimality equation into an update rule.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="05-bellman-optimal.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The Bellman Optimality Equation</p>
      </div>
    </a>
    <a class="right-next"
       href="07-monte-carlo-td.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Monte Carlo vs Temporal Difference Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-evaluation">Policy Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-improvement">Policy Improvement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-iteration">Policy Iteration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#value-iteration">Value Iteration</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>